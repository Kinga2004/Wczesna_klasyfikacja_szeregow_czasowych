{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "037e1309",
   "metadata": {},
   "source": [
    "https://github.com/Eukla/ETS/tree/master/ets/algorithms\n",
    "\n",
    "https://github.com/JakubBilski/CALIMERA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1b5130",
   "metadata": {},
   "source": [
    "# ECTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02912e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "from scipy.spatial import distance\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from typing import Tuple, List, Sequence, Dict, Optional\n",
    "import multiprocessing as mp\n",
    "\n",
    "class ECTS():\n",
    "    \"\"\"Algorytm ECTS\"\"\"\n",
    "\n",
    "    def __init__(self, timestamps, support: float):\n",
    "        \"\"\"\n",
    "        Tworzy instancję ECTS.\n",
    "        :param timestamps: lista znaczników czasu dla wczesnych prognoz\n",
    "        :param support: minimalny próg wsparcia\n",
    "        \"\"\"\n",
    "        self.rnn: Dict[int, Dict[int, List]] = dict()\n",
    "        self.nn: Dict[int, Dict[int, List]] = dict()\n",
    "        self.data: Optional[pd.DataFrame] = None\n",
    "        self.labels: Optional[pd.Series] = None\n",
    "        self.mpl: Dict[int, Optional[int]] = dict()\n",
    "        self.timestamps = timestamps\n",
    "        self.support = support\n",
    "        self.clusters: Dict[int, List[int]] = dict()\n",
    "        self.occur: Dict[int, int] = dict()\n",
    "        self.correct: Optional[List[Optional[int]]] = None\n",
    "\n",
    "    def train(self, train_data: pd.DataFrame, labels: Sequence[int]) -> None:\n",
    "        \"\"\"\n",
    "        Trenowanie modelu.\n",
    "        :param train_data: zbiór treningowy jako DataFrame\n",
    "        :param labels: zbiór przypisanych klas do szeregów ze zbioru treningowego\n",
    "        \"\"\"\n",
    "        self.data = train_data\n",
    "        self.labels = labels\n",
    "\n",
    "        for index, value in self.labels.value_counts().items():\n",
    "            self.occur[index] = value\n",
    "\n",
    "        time_pos = 0\n",
    "        for e in self.timestamps:\n",
    "            product = self.__nn_non_cluster(time_pos) \n",
    "            self.rnn[e] = product[1]\n",
    "            self.nn[e] = product[0]\n",
    "            time_pos += 1\n",
    "        temp = {}\n",
    "        finished = {}  \n",
    "        for e in reversed(self.timestamps):\n",
    "            for index, row in self.data.iterrows():\n",
    "                if index not in temp:\n",
    "                    self.mpl[index] = e\n",
    "                    finished[index] = 0  \n",
    "\n",
    "                else:\n",
    "                    if finished[index] == 1: \n",
    "                        continue\n",
    "\n",
    "                    if self.rnn[e][index] is not None:\n",
    "                        self.rnn[e][index].sort()\n",
    "                    if temp[index] is not None:\n",
    "                        temp[index].sort()\n",
    "\n",
    "                    if self.rnn[e][index] == temp[index]: \n",
    "                        self.mpl[index] = e\n",
    "\n",
    "                    else:  \n",
    "                        finished[index] = 1\n",
    "                temp[index] = self.rnn[e][index]\n",
    "        self.__mpl_clustering()\n",
    "\n",
    "    def __nn_non_cluster(self, prefix: int):\n",
    "        \"\"\"Funkcja znajduje zbiór NN i RNN dla wszystkich szeregów czasowych o zadanej długości prefiksu.\n",
    "        :param prefix: długość prefiksu\n",
    "        :return: słowniki przechowujące zbiory NN i RNN\"\"\"\n",
    "        nn = {}\n",
    "        rnn = {}\n",
    "        neigh = NearestNeighbors(n_neighbors=2, metric='euclidean').fit(self.data.iloc[:, 0:prefix + 1])\n",
    "        def something(row):\n",
    "            return neigh.kneighbors([row])\n",
    "\n",
    "        result_data = self.data.iloc[:, 0:prefix + 1].apply(something, axis=1)\n",
    "        for index, value in result_data.items():\n",
    "            if index not in nn:\n",
    "                nn[index] = []\n",
    "            if index not in rnn:\n",
    "                rnn[index] = []\n",
    "            for item in value[1][0]:\n",
    "                if item != index:\n",
    "                    nn[index].append(item)\n",
    "                    if item not in rnn:\n",
    "                        rnn[item] = [index]\n",
    "                    else:\n",
    "                        rnn[item].append(index)\n",
    "        return nn, rnn\n",
    "\n",
    "    def __cluster_distance(self, cluster_a: Sequence[int], cluster_b: Sequence[int]):\n",
    "        \"\"\"\n",
    "        Funkcja oblicz odległość między dwoma klastami i szuka minimalnej odległości między wszystkimi parami elementów z dwóch klastrów.\n",
    "        :param cluster_a: pierwszy klaster\n",
    "        :param cluster_b: drugi klaster\n",
    "        :return:  odległość\n",
    "        \"\"\"\n",
    "\n",
    "        min_distance = float(\"inf\")\n",
    "        for i in cluster_a:\n",
    "            for j in cluster_b:\n",
    "                d = distance.euclidean(self.data.iloc[i], self.data.iloc[j])\n",
    "                if min_distance > d:\n",
    "                    min_distance = d\n",
    "\n",
    "        return min_distance\n",
    "\n",
    "    def nn_cluster(self, cl_key: int, cluster_index: Sequence[int]):\n",
    "        \"\"\"\n",
    "        Funkcja szuka najbliższego klastra używając __cluster_distance.\n",
    "        :param cluster_index: lista indeksów serii należących do tego klastra\n",
    "        :param cl_key: klucz klastra w słowniku\n",
    "        \"\"\"\n",
    "        dist = float(\"inf\")\n",
    "        candidate = [] \n",
    "\n",
    "        for key, value in self.clusters.items(): \n",
    "\n",
    "            if cl_key == key: \n",
    "                continue\n",
    "            temp = self.__cluster_distance(cluster_index, value) \n",
    "\n",
    "            if dist >= temp: \n",
    "                dist = temp\n",
    "                candidate = [key]\n",
    "        return candidate\n",
    "\n",
    "    def __rnn_cluster(self, e: int, cluster: List[int]):\n",
    "        \"\"\"\n",
    "        Oblicza RNN klastra dla obecnegp prefiksu.\n",
    "        :param e: prefiks, dla którego szukamy zbioru RNN\n",
    "        :param cluster: klaster, dla którego szukamy zbioru RNN\n",
    "        \"\"\"\n",
    "\n",
    "        rnn = set()\n",
    "        complete = set()\n",
    "        for item in cluster:\n",
    "            rnn.union(self.rnn[e][item])\n",
    "        for item in rnn:\n",
    "            if item not in cluster:\n",
    "                complete.add(item)\n",
    "        return complete\n",
    "\n",
    "    def __mpl_calculation(self, cluster: List[int]):\n",
    "        \"\"\"\n",
    "        Funkcja szuka MPL dla klastrów.\n",
    "        :param cluster: klaster, dla którego szukamy MPL\n",
    "        \"\"\"\n",
    "        index = self.labels[cluster[0]]\n",
    "        if self.support > len(cluster) / self.occur[index]:\n",
    "            return #nie liczymy, jeśli klaster jest zbyt mały\n",
    "        mpl_rnn = self.timestamps[len(self.timestamps) - 1] \n",
    "        mpl_nn = self.timestamps[len(self.timestamps) - 1]\n",
    "\n",
    "        curr_rnn = self.__rnn_cluster(self.timestamps[len(self.timestamps) - 1], cluster)  # RNN dla pełniej długości\n",
    "\n",
    "        for e in reversed(self.timestamps):\n",
    "            temp = self.__rnn_cluster(e, cluster)  # RNN dla kolejnych długości\n",
    "            if not curr_rnn - temp: \n",
    "                mpl_rnn = e\n",
    "            else:\n",
    "                break\n",
    "            curr_rnn = temp\n",
    "\n",
    "        rule_broken = 0\n",
    "        for e in reversed(self.timestamps):  # NN dla kolejnych długości\n",
    "            for series in cluster:  # Dla wszystkich szeregów czasowych\n",
    "                for my_tuple in self.nn[e][series]:  \n",
    "                    if my_tuple not in cluster:\n",
    "                        rule_broken = 1\n",
    "                        break\n",
    "                if rule_broken == 1:\n",
    "                    break\n",
    "            if rule_broken == 1:\n",
    "                break\n",
    "            else:\n",
    "                mpl_nn = e\n",
    "        for series in cluster:\n",
    "            pos = max(mpl_rnn, mpl_nn)  \n",
    "            if self.mpl[series] > pos:\n",
    "                self.mpl[series] = pos\n",
    "\n",
    "    def __mpl_clustering(self):\n",
    "        \"\"\"Funkcja wywołuje grupowanie hierarchiczne\"\"\"\n",
    "        n = self.data.shape[0]\n",
    "        redirect = {}\n",
    "        discriminative = 0\n",
    "\n",
    "        # Każdy szereg jako osobny klaster\n",
    "        for index, row in self.data.iterrows():\n",
    "            self.clusters[index] = [index]\n",
    "            redirect[index] = index\n",
    "\n",
    "        result = []\n",
    "        max_iterations = n * n  # maksymalna liczba iteracji, zabezpieczenie\n",
    "        iter_count = 0\n",
    "\n",
    "        while n > 1:\n",
    "            iter_count += 1\n",
    "            if iter_count > max_iterations:\n",
    "                break\n",
    "\n",
    "            closest = {}\n",
    "\n",
    "            # Wyznaczamy najbliższy klaster dla każdego klastra\n",
    "            for key, cluster in self.clusters.items():\n",
    "                closest[key] = self.nn_cluster(key, cluster)\n",
    "\n",
    "            merged = False\n",
    "\n",
    "            for key, candidates in closest.items():\n",
    "                for item in list(candidates):\n",
    "                    if key in closest.get(item, []):\n",
    "                        # Sprawdzenie, czy nie są już w tym samym klastrze\n",
    "                        if redirect[item] == redirect[key]:\n",
    "                            continue\n",
    "\n",
    "                        self.clusters[redirect[key]] += self.clusters[redirect[item]]\n",
    "                        del self.clusters[redirect[item]]\n",
    "                        n -= 1\n",
    "                        redirect[item] = redirect[key]\n",
    "\n",
    "                        result = [self.labels.loc[idx] for idx in self.clusters[redirect[key]]]\n",
    "                        if len(set(result)) == 1:\n",
    "                            discriminative += 1\n",
    "                            self.__mpl_calculation(self.clusters[redirect[key]])\n",
    "\n",
    "                        for k in redirect:\n",
    "                            if redirect[k] == item:\n",
    "                                redirect[k] = redirect[key]\n",
    "\n",
    "                        merged = True\n",
    "\n",
    "            # Jeśli nie połączono żadnego klastra, kończymy pętlę\n",
    "            if not merged:\n",
    "                break\n",
    "\n",
    "            discriminative = 0\n",
    "\n",
    "    def predict(self, test_data: pd.DataFrame) -> List[Tuple[int, int]]:\n",
    "        \"\"\"Faza predykcji.\"\"\"\n",
    "        predictions = []\n",
    "        nn = []\n",
    "        candidates = [] \n",
    "        cand_min_mpl = []\n",
    "        for test_index, test_row in test_data.iterrows():\n",
    "            for e in self.timestamps:\n",
    "                neigh = NearestNeighbors(n_neighbors=1, metric='euclidean').fit(self.data.iloc[:, 0:e + 1])\n",
    "                neighbors = neigh.kneighbors([test_row[0:e + 1]])\n",
    "                candidates.clear()\n",
    "                cand_min_mpl.clear()\n",
    "                nn = neighbors[1]\n",
    "                for i in nn:\n",
    "                    if e >= self.mpl[i[0]]:\n",
    "                        candidates.append((self.mpl[i[0]], self.labels[i[0]])) \n",
    "                if len(candidates) > 1: \n",
    "                    candidates.sort(key=lambda x: x[0])\n",
    "                    for candidate in candidates:\n",
    "\n",
    "                        if candidate[0] == candidates[0][0]:\n",
    "                            cand_min_mpl.append(candidate) \n",
    "                        else:\n",
    "                            break \n",
    "                    predictions.append((e, max(set(cand_min_mpl), key=cand_min_mpl.count)))  \n",
    "                    break\n",
    "                elif len(candidates) == 1: \n",
    "                    predictions.append((e, candidates[0][1]))\n",
    "                    break\n",
    "            if candidates == 0:\n",
    "                predictions.append((self.timestamps[-1], 0))\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a45a6d8",
   "metadata": {},
   "source": [
    "# TEASER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ce394ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msktime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mearly_classification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TEASER\n",
      "File \u001b[1;32mc:\\Users\\admmass\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sktime\\__init__.py:10\u001b[0m\n\u001b[0;32m      6\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.39.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msktime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_maint\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n",
      "File \u001b[1;32mc:\\Users\\admmass\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sktime\\utils\\__init__.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Utility functionality.\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msktime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mestimator_checks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_estimator\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msktime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplotting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_series, plot_windows\n\u001b[0;32m      6\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck_estimator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplot_series\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplot_windows\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\admmass\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sktime\\utils\\plotting.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m simplefilter, warn\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msktime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatatypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_check\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_is_scitype\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msktime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mforecasting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_evaluation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_y_X_train_test_global\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_series\u001b[39m(\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;241m*\u001b[39mseries,\n\u001b[0;32m     17\u001b[0m     labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m     pred_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     25\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\admmass\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sktime\\datatypes\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Module exports: data type definitions, checks, validation, fixtures, converters.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msktime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatatypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_check\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      4\u001b[0m     check_is_error_msg,\n\u001b[0;32m      5\u001b[0m     check_is_mtype,\n\u001b[0;32m      6\u001b[0m     check_is_scitype,\n\u001b[0;32m      7\u001b[0m     check_raise,\n\u001b[0;32m      8\u001b[0m     mtype,\n\u001b[0;32m      9\u001b[0m     scitype,\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msktime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatatypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_convert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert, convert_to\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msktime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatatypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_examples\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_examples\n",
      "File \u001b[1;32mc:\\Users\\admmass\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sktime\\datatypes\\_check.py:30\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lru_cache\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msktime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatatypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_common\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _metadata_requested, _ret\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msktime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatatypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_registry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     32\u001b[0m     AMBIGUOUS_MTYPES,\n\u001b[0;32m     33\u001b[0m     SCITYPE_LIST,\n\u001b[0;32m     34\u001b[0m     generate_mtype_cls_list,\n\u001b[0;32m     35\u001b[0m     mtype_to_scitype,\n\u001b[0;32m     36\u001b[0m )\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_check_dict\u001b[39m(soft_deps\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresent\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\admmass\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sktime\\datatypes\\_base\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Base module for datatypes.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msktime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatatypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseConverter, BaseDatatype, BaseExample\n\u001b[0;32m      5\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseConverter\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseDatatype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseExample\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\admmass\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sktime\\datatypes\\_base\\_base.py:6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"Base class for data types.\"\"\"\u001b[39;00m\n\u001b[0;32m      4\u001b[0m __author__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfkiraly\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msktime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseObject\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msktime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatatypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_common\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _ret\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msktime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeep_equals\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deep_equals\n",
      "File \u001b[1;32mc:\\Users\\admmass\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sktime\\base\\__init__.py:14\u001b[0m\n\u001b[0;32m      5\u001b[0m __author__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmloning\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRNKuhns\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfkiraly\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      6\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseObject\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseEstimator\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m ]\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msktime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseEstimator, BaseObject\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msktime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base_panel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BasePanelMixin\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msktime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_meta\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HeterogenousMetaEstimator\n",
      "File \u001b[1;32mc:\\Users\\admmass\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sktime\\base\\_base.py:64\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskbase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseObject \u001b[38;5;28;01mas\u001b[39;00m _BaseObject\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskbase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TagAliaserMixin \u001b[38;5;28;01mas\u001b[39;00m _TagAliaserMixin\n\u001b[1;32m---> 64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseEstimator \u001b[38;5;28;01mas\u001b[39;00m _SklearnBaseEstimator\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msktime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m SKTIME_VERSION\n",
      "File \u001b[1;32mc:\\Users\\admmass\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\__init__.py:73\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# `_distributor_init` allows distributors to run custom init code.\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# For instance, for the Windows wheel, this is used to pre-load the\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# vcomp shared library runtime for OpenMP embedded in the sklearn/.libs\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401 E402\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     __check_build,\n\u001b[0;32m     71\u001b[0m     _distributor_init,\n\u001b[0;32m     72\u001b[0m )\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     76\u001b[0m _submodules \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompose\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    115\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\admmass\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HTMLDocumentationLinkMixin, estimator_html_repr\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n",
      "File \u001b[1;32mc:\\Users\\admmass\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\__init__.py:15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _joblib, metadata_routing\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bunch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_chunking\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_batches, gen_even_slices\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Make _safe_indexing importable from here for backward compat as this particular\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# helper is considered semi-private and typically very useful for third-party\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# libraries that want to comply with scikit-learn's estimator API. In particular,\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# _safe_indexing was included in our public API documentation despite the leading\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# `_` in its name.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\admmass\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_chunking.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchunk_generator\u001b[39m(gen, chunksize):\n\u001b[0;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m    chunk may have a length less than ``chunksize``.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\admmass\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mInvalidParameterError\u001b[39;00m(\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m     21\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Custom exception to be raised when the parameter of a class/method/function\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03m    does not have a valid type or value.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\admmass\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config \u001b[38;5;28;01mas\u001b[39;00m _get_config\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataConversionWarning, NotFittedError, PositiveSpectrumWarning\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_array_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _asarray_with_order, _is_numpy_namespace, get_namespace\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _deprecate_force_all_finite\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ComplexWarning, _preserve_dia_indices_dtype\n",
      "File \u001b[1;32mc:\\Users\\admmass\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_array_api.py:14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msp\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mspecial\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_version\n",
      "File \u001b[1;32mc:\\Users\\admmass\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\special\\__init__.py:817\u001b[0m\n\u001b[0;32m    812\u001b[0m _load_libsf_error_state()\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sf_error\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SpecialFunctionWarning, SpecialFunctionError\n\u001b[1;32m--> 817\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _ufuncs\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ufuncs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    820\u001b[0m \u001b[38;5;66;03m# Replace some function definitions from _ufuncs to add Array API support\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\admmass\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\special\\_ufuncs.pyx:1\u001b[0m, in \u001b[0;36minit scipy.special._ufuncs\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:404\u001b[0m, in \u001b[0;36mparent\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sktime.classification.early_classification import TEASER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce94a75f",
   "metadata": {},
   "source": [
    "# CALIMERA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889b75bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sktime.transformations.panel.rocket import MiniRocketMultivariate\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "\n",
    "class CALIMERA:\n",
    "    def __init__(self, delay_penalty):\n",
    "        self.delay_penalty = delay_penalty\n",
    "\n",
    "    def _generate_timestamps(max_timestamp):\n",
    "        NUM_TIMESTAMPS = 20\n",
    "        num_intervals_between_timestamps = min(NUM_TIMESTAMPS-1, max_timestamp)\n",
    "        step = max_timestamp // num_intervals_between_timestamps\n",
    "        timestamps = np.arange(max(2, step), max_timestamp+step, step).astype(np.int32)\n",
    "        timestamps[-1] = max_timestamp\n",
    "        return timestamps\n",
    "\n",
    "    def _learn_feature_extractors(X, timestamps):\n",
    "        extractors = []\n",
    "        for timestamp in timestamps:\n",
    "            if timestamp < 9:\n",
    "                extractors.append(lambda x: x.reshape(x.shape[0], -1))\n",
    "            else:\n",
    "                X_sub = X[:, :, :timestamp]\n",
    "                extractors.append(MiniRocketMultivariate().fit(X_sub).transform)\n",
    "        return extractors\n",
    "\n",
    "    def _get_features(X, feature_extractors, timestamps):\n",
    "        features = [[] for i in range(timestamps.shape[0])]\n",
    "        for i in range(timestamps.shape[0]):\n",
    "            timestamp = timestamps[i]\n",
    "            X_sub = X[:, :, :timestamp]\n",
    "            feature = feature_extractors[i](X_sub)\n",
    "            features[i] = np.asarray(feature)\n",
    "            features[i] = features[i].reshape(features[i].shape[0], -1)\n",
    "        return features\n",
    "\n",
    "    def _learn_classifiers(features, ys, timestamps):\n",
    "        T = timestamps.shape[0]\n",
    "        classifiers = [None for t in range(T)]\n",
    "\n",
    "        for t in range(T):\n",
    "            classifier = WeakClassifier()\n",
    "            classifier.fit(features[t], ys)\n",
    "            classifiers[t] = classifier\n",
    "\n",
    "        return classifiers\n",
    "\n",
    "    def _generate_data_for_training_stopping_module(classifiers):\n",
    "        predictors = []\n",
    "        costs = []\n",
    "        for classifier in classifiers:\n",
    "            costs.append(classifier.costs_for_training_stopping_module)\n",
    "            predictors.append([\n",
    "                _scores_to_predictors(s) \n",
    "                for s in classifier.predictors_for_training_stopping_module\n",
    "            ])\n",
    "        return np.asarray(predictors), np.asarray(costs)\n",
    "\n",
    "    def fit(self, X_train, labels):\n",
    "        timestamps = CALIMERA._generate_timestamps(max_timestamp=X_train.shape[-1])\n",
    "        self.feature_extractors = CALIMERA._learn_feature_extractors(X_train, timestamps)\n",
    "        features_train = CALIMERA._get_features(X_train, self.feature_extractors, timestamps)\n",
    "        self.classifiers = CALIMERA._learn_classifiers(features_train, labels, timestamps)\n",
    "        predictors, costs = CALIMERA._generate_data_for_training_stopping_module(self.classifiers)\n",
    "        self.stopping_module = StoppingModule()\n",
    "        self.stopping_module.fit(\n",
    "            predictors,\n",
    "            costs,\n",
    "            timestamps,\n",
    "            self.delay_penalty,\n",
    "            KernelRidgeRegressionWrapper\n",
    "        )\n",
    "        self.timestamps = timestamps\n",
    "\n",
    "    def test(self, X):\n",
    "        n = X.shape[0]\n",
    "        stop_timestamps = []\n",
    "        predicted_y = []\n",
    "        for j in range(n):\n",
    "            for t in range(self.timestamps.shape[0]):\n",
    "                X_sub = X[j, :, :self.timestamps[t]]\n",
    "                X_sub = X_sub.reshape(1, -1, X_sub.shape[-1])\n",
    "                features = np.asarray(self.feature_extractors[t](X_sub))\n",
    "                scores = self.classifiers[t].get_scores(features.reshape(1, -1))[0]\n",
    "                predictors = _scores_to_predictors(scores)\n",
    "                should_stop = (\n",
    "                    t==(self.timestamps.shape[0]-1) or \\\n",
    "                        self.stopping_module.should_stop(predictors, t)\n",
    "                )\n",
    "                if should_stop:\n",
    "                    predicted_label = self.classifiers[t].predict(features.reshape(1, -1))[0]\n",
    "                    stop_timestamps.append(self.timestamps[t])\n",
    "                    predicted_y.append(predicted_label)\n",
    "                    break\n",
    "        return stop_timestamps, predicted_y\n",
    "\n",
    "\n",
    "class KernelRidgeRegressionWrapper:\n",
    "    def __init__(self):\n",
    "        self.model = KernelRidge(kernel=\"rbf\")\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "\n",
    "class WeakClassifier:\n",
    "    def normalize_X(self, X):\n",
    "        return (X - self.feature_means) / self.feature_norms\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        RC_ALPHAS = np.logspace(-3, 3, 10)\n",
    "\n",
    "        self.feature_means = np.mean(X, axis=0)\n",
    "        self.feature_norms = np.linalg.norm(X, axis=0)\n",
    "        self.feature_norms[self.feature_norms == 0] = 1.0\n",
    "\n",
    "        uncalibrated_clf = RidgeClassifierCV(\n",
    "            alphas=RC_ALPHAS, store_cv_values=True, scoring='accuracy')\n",
    "        normalized_X = self.normalize_X(X)\n",
    "        uncalibrated_clf.fit(normalized_X, y)\n",
    "\n",
    "        chosen_alpha_index = np.where(RC_ALPHAS == uncalibrated_clf.alpha_)\n",
    "        X_scores = uncalibrated_clf.cv_values_[:, :, chosen_alpha_index]\n",
    "        X_scores = X_scores.reshape((X_scores.shape[0], X_scores.shape[1]))\n",
    "        X_scores = X_scores + uncalibrated_clf.intercept_\n",
    "\n",
    "        # transform to uncalibrated probabilities\n",
    "        exped_X_scores = np.exp(X_scores)\n",
    "        if len(uncalibrated_clf.classes_) == 2:\n",
    "            X_probab = exped_X_scores / (exped_X_scores + np.exp(-X_scores))\n",
    "        else:\n",
    "            X_probab = exped_X_scores / np.sum(exped_X_scores, axis=1)[:,None]\n",
    "\n",
    "        # walkaround to use L1O validation data in an sklearn calibrator and save some time\n",
    "        mockup_clf = MockupClassifierForPassingValidationDataToSklearnCalibrator(\n",
    "            X_probab, uncalibrated_clf.classes_\n",
    "        )\n",
    "        calibrated_clf = CalibratedClassifierCV(mockup_clf, method=\"sigmoid\", cv=\"prefit\")\n",
    "        mockup_X = np.zeros((y.shape[0], 1))\n",
    "        calibrated_clf.fit(mockup_X, y)\n",
    "\n",
    "        # generate data for stopping module training\n",
    "        self.costs_for_training_stopping_module = 1.0 - np.max(\n",
    "            calibrated_clf.predict_proba(mockup_X), axis=1\n",
    "        )\n",
    "        self.predictors_for_training_stopping_module = X_scores\n",
    "\n",
    "        # actual classification can be performed with uncalibrated clfs\n",
    "        self.clf = uncalibrated_clf \n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(self.normalize_X(X))\n",
    "\n",
    "    def get_scores(self, X):\n",
    "        return np.atleast_2d(self.clf.decision_function(self.normalize_X(X)))\n",
    "\n",
    "    def get_labels(self):\n",
    "        return self.clf.classes_\n",
    "\n",
    "\n",
    "class MockupClassifierForPassingValidationDataToSklearnCalibrator:\n",
    "    def __init__(self, mockup_scores, classes):\n",
    "        self.mockup_scores = mockup_scores\n",
    "        self.classes_ = classes\n",
    "        self._estimator_type = \"classifier\"\n",
    "\n",
    "    def fit(self):\n",
    "        pass\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        return self.mockup_scores\n",
    "\n",
    "\n",
    "class StoppingModule:\n",
    "    def fit(self, predictors, original_costs, timestamps, alpha, REGRESSOR_WAIT):\n",
    "        costs = np.copy(original_costs)\n",
    "\n",
    "        T = timestamps.shape[0]\n",
    "        n = predictors.shape[1]\n",
    "\n",
    "        for t in range(timestamps.shape[0]):\n",
    "            costs[t, :] += alpha * (timestamps[t] / timestamps[-1])\n",
    "\n",
    "        self.halters = [None for t in range(T-1)]\n",
    "\n",
    "        for t in range(T-2, -1, -1):\n",
    "            X = predictors[t, :].squeeze()\n",
    "            X = X.reshape(X.shape[0], -1)\n",
    "            y = costs[t+1, :] - costs[t, :]\n",
    "\n",
    "            model = REGRESSOR_WAIT().fit(X, y)\n",
    "\n",
    "            self.halters[t] = model\n",
    "            predicted_cost_difference = model.predict(X)\n",
    "            for j in range(n):\n",
    "                if predicted_cost_difference[j] < 0:\n",
    "                    costs[t, j] = costs[t+1, j]\n",
    "\n",
    "    def should_stop(self, predictors, t):\n",
    "        predicted_cost_difference = self.halters[t].predict([predictors])\n",
    "        return predicted_cost_difference > 0\n",
    "\n",
    "\n",
    "def _scores_to_predictors(scores):\n",
    "    if len(scores) == 1:\n",
    "        return scores\n",
    "    highest_score = np.max(scores)\n",
    "    second_highest_score = np.partition(scores, -2)[-2]\n",
    "    score_diff_stolen_from_teaser = highest_score - second_highest_score\n",
    "    predictors = np.zeros(scores.shape[0]+2)\n",
    "    predictors[:-2] = scores\n",
    "    predictors[-2] = score_diff_stolen_from_teaser\n",
    "    predictors[-1] = highest_score\n",
    "    return predictors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
